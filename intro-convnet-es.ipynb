{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Clasificando rostros humanos usando redes neuronales convolucionales (ConvNet's)\n",
    "\n",
    "El objetivo de este taller es introducir la arquitectura de red neuronal convolucional clásica (ConvNet) LeNet-5 a los asistentes usando python, tensor-flow y sci-kit learn. Los asistentes aprenderán los conceptos básicos y cómo construir una ConvNet clasificando si sí o no una imagen tiene un rostro humano.\n",
    "\n",
    "Puntos del taller:\n",
    "\n",
    "* Breve introducción a los Fundamentos de la Red Neuronal Convolucional usando la Arquitectura LeNet-5\n",
    "* Preparación de datos usando numpy y sklearn\n",
    "* Construyendo una ConvNet con Tensor-flow\n",
    "* Uso de ConvNet para detectar sí o no una imagen tiene una cara humana\n",
    "* Conclusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Library and dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import scipy.misc\n",
    "import glob\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import flatten\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from IPython.display import Markdown, display\n",
    "from scipy import signal\n",
    "import time\n",
    "import random\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convolución de matrices\n",
    "\n",
    "Es una operación entre dos matrices donde a la matriz A se le aplica otra matriz B también se puede llamar filtro o kernel, para dar una idea de que hace esta operación, las próximas celdas muestran un ejemplo con las matrices A = x y B = W. Las redes ConvNets se caracterizan por hacer uso intensivo de convoluciones para la extracción automática de características de las imágenes, mas adelante este notebook muestra la arquitectura de red LeNet-5 que usa capas de convolución y de submuestreo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = np.array([\n",
    "    [ 8, 8, 8, 8],\n",
    "    [ 8, 8, 8, 8],\n",
    "    [ 8, 8, 8, 8],\n",
    "    [ 8, 8, 8, 8]\n",
    "])\n",
    "\n",
    "W = np.array([\n",
    "    [2, 1],\n",
    "    [0, 3]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Valid padding\n",
    "$$ x = \\begin{bmatrix}\n",
    "    8 & 8 & 8 & 8\\\\\n",
    "    8 & 8 & 8 & 8\\\\\n",
    "    8 & 8 & 8 & 8\\\\\n",
    "    8 & 8 & 8 & 8\n",
    "\\end{bmatrix} \\;\\;\\; W = \\begin{bmatrix}\n",
    "    2 & 1\\\\\n",
    "    0 & 3\n",
    "\\end{bmatrix}\\;\\;\\;  x * W (convolution) =\\begin{bmatrix}\n",
    "    48_{1,1} & 48_{1,2} & 48_{1,3}\\\\\n",
    "    48_{2,1} & 48_{2,2} & 48_{2,3}\\\\\n",
    "    48_{3,1} & 48_{3,2} & 48_{3,3}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "$$ (x * W)_{1,1} = \\begin{bmatrix}\n",
    "    8 * 2& 8 * 1\\\\\n",
    "    8 * 0& 8 * 3\n",
    "\\end{bmatrix} \\;\\;\\; => \\begin{bmatrix}\n",
    "    16 & 8\\\\\n",
    "    0  & 24\n",
    "\\end{bmatrix}\\;\\;\\; => (unroll)\\begin{bmatrix}\n",
    "    16 + 8 + 0 + 24\n",
    "\\end{bmatrix}\\;\\;\\;    => \\begin{bmatrix}\n",
    "    48\n",
    "\\end{bmatrix}_{1,1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "signal.convolve2d(x, W, mode='valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Same (with padding) applies mirror to W only when mode is same\n",
    "$$ x = \\begin{bmatrix}\n",
    "    0 & 0 & 0 & 0 & 0 \\\\\n",
    "    0 & 8 & 8 & 8 & 8 \\\\\n",
    "    0 & 8 & 8 & 8 & 8 \\\\\n",
    "    0 & 8 & 8 & 8 & 8 \\\\\n",
    "    0 & 8 & 8 & 8 & 8 \\\\\n",
    "\\end{bmatrix} \\;\\;\\; mirror(W) = W' = \\begin{bmatrix}\n",
    "    3 & 0\\\\\n",
    "    1 & 2\n",
    "\\end{bmatrix}\\;\\;\\;  x * W' (convolution) =\\begin{bmatrix}\n",
    "    16_{1,1} & 24_{1,2} & 24_{1,3} & 24_{1,4}\\\\\n",
    "    16_{2,1} & 48_{2,2} & 48_{2,3} & 48_{2,4}\\\\\n",
    "    16_{3,1} & 48_{3,2} & 48_{3,3} & 48_{3,4}\\\\\n",
    "    16_{4,1} & 48_{4,2} & 48_{4,3} & 48_{4,4}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "$$ (x * W')_{1,1} = \\begin{bmatrix}\n",
    "    0 * 3& 0 * 0\\\\\n",
    "    0 * 1& 8 * 2\n",
    "\\end{bmatrix} \\;\\;\\; => \\begin{bmatrix}\n",
    "    0 & 0\\\\\n",
    "    0  & 16\n",
    "\\end{bmatrix}\\;\\;\\; => (unroll)\\begin{bmatrix}\n",
    "    0 + 0 + 0 + 16\n",
    "\\end{bmatrix}\\;\\;\\;    => \\begin{bmatrix}\n",
    "    16\n",
    "\\end{bmatrix}_{1,1}$$\n",
    "\n",
    "$$ (x * W')_{1,2} = \\begin{bmatrix}\n",
    "    0 * 3& 0 * 0\\\\\n",
    "    8 * 1& 8 * 2\n",
    "\\end{bmatrix} \\;\\;\\; => \\begin{bmatrix}\n",
    "    0 & 0\\\\\n",
    "    8  & 16\n",
    "\\end{bmatrix}\\;\\;\\; => (unroll)\\begin{bmatrix}\n",
    "    0 + 0 + 8 + 16\n",
    "\\end{bmatrix}\\;\\;\\;    => \\begin{bmatrix}\n",
    "    24\n",
    "\\end{bmatrix}_{1,2}$$\n",
    "\n",
    "$$ (x * W')_{2,1} = \\begin{bmatrix}\n",
    "    8 * 3& 8 * 0\\\\\n",
    "    8 * 1& 8 * 2\n",
    "\\end{bmatrix} \\;\\;\\; => \\begin{bmatrix}\n",
    "    24 & 0\\\\\n",
    "    8  & 16\n",
    "\\end{bmatrix}\\;\\;\\; => (unroll)\\begin{bmatrix}\n",
    "    24 + 0 + 8 + 16\n",
    "\\end{bmatrix}\\;\\;\\;    => \\begin{bmatrix}\n",
    "    48\n",
    "\\end{bmatrix}_{2,1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "signal.convolve2d(x, W, mode=\"same\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### Las próximas celdas muestran como usar convoluciones sobre una imagen con un kernel conocido como Sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sobel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype = np.float)\n",
    "sobel_y = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], dtype = np.float)\n",
    "\n",
    "image = cv2.imread('./data/faces/no_faces/n02086240_936.jpg', 0)\n",
    "print(sobel_x, \"Sobel kernel X\\n\")\n",
    "print(sobel_y, \"Sobel kernel Y\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "image_sobel_x = signal.convolve2d(image, sobel_x, mode='valid')\n",
    "image_sobel_y = signal.convolve2d(image, sobel_y, mode='valid')\n",
    "fig,((a,b,c)) = plt.subplots(1,3, figsize=(12,12))\n",
    "\n",
    "a.imshow(image, cmap=\"gray\")\n",
    "b.imshow(image_sobel_x, cmap=\"gray\")\n",
    "c.imshow(image_sobel_y, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Aplicando convoluciones con kernels aleatorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W1 = np.random.randint(-100, 100, (3,3))\n",
    "W2 = np.random.randint(-2, 2, (3,3))\n",
    "image_rand_w1_x = signal.convolve2d(image, W1, mode='valid')\n",
    "image_rand_w2_x = signal.convolve2d(image, W2, mode='valid')\n",
    "fig,((a,b,c)) = plt.subplots(1,3, figsize=(12,12))\n",
    "\n",
    "a.imshow(image, cmap=\"gray\")\n",
    "b.imshow(image_rand_w1_x, cmap=\"gray\")\n",
    "c.imshow(image_rand_w2_x, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Implementación de convolución en tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "_x = np.array([image[:, :, np.newaxis].astype(np.float32)])\n",
    "x = tf.get_variable('X', initializer=_x)\n",
    "W = tf.get_variable('weights', [5, 5, 1, 16], initializer=tf.truncated_normal_initializer(stddev=5e-2, dtype=tf.float32), dtype=tf.float32)\n",
    "conv1 = tf.nn.conv2d(x, W, [1, 1, 1, 1], 'SAME')\n",
    "result = None\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    result = sess.run(conv1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig, draws = plt.subplots(4,4, figsize=(12,12))\n",
    "draws = draws.reshape(-1)\n",
    "fig.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "\n",
    "for idx in range(result.shape[-1]):    \n",
    "    draws[idx].imshow(result[0, :, :, idx], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Submuestreo de imagenes (MaxPooling)\n",
    "\n",
    "Las ConvNets también usan capas de submuestreo para reducir el espacio de características y también ayuda a generalizar el modelo resultante.\n",
    "\n",
    "Las celdas siguientes muestran como usar submuestreo usando un código de ejemplo de [stackoverflow](https://stackoverflow.com/questions/42463172/how-to-perform-max-mean-pooling-on-a-2d-array-using-numpy) sobre una matriz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Max Pooling\n",
    "\n",
    "$$ x = \\begin{bmatrix}\n",
    " 304 & -779 & -424 &  287 \\\\\n",
    "-385 &  617 & -665 &  738 \\\\\n",
    " 497 &  974 &  390 & -678 \\\\\n",
    "-669 & -854 &  661 & -919 \n",
    "\\end{bmatrix} \\;\\;\\; Maxpool(x, kernelSize: 2, slide: 2) =\\begin{bmatrix}\n",
    "    617 & 738\\\\\n",
    "    974 & 661\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = np.array(\n",
    "    [[ 304, -779, -424,  287],\n",
    "     [-385,  617, -665,  738],\n",
    "     [ 497,  974,  390, -678],\n",
    "     [-669, -854,  661, -919]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "k_size = 2\n",
    "MK = x.shape[0] // k_size\n",
    "NL = x.shape[1] // k_size\n",
    "print(x[:MK*k_size, :NL*k_size].reshape(MK, k_size, NL, k_size).max(axis=(1, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "k_size = 5\n",
    "MK = image.shape[0] // k_size\n",
    "NL = image.shape[1] // k_size\n",
    "\n",
    "image_max_pool_2 = image[:MK*k_size, :NL*k_size].reshape(MK, k_size, NL, k_size).max(axis=(1, 3))\n",
    "fig,((a,b)) = plt.subplots(1,2, figsize=(12,12))\n",
    "\n",
    "a.imshow(image, cmap=\"gray\")\n",
    "b.imshow(image_max_pool_2, cmap=\"gray\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Implementación de maxpooling en tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "_x = np.array([image[:, :, np.newaxis].astype(np.float32)])\n",
    "x = tf.get_variable('X', initializer=_x)\n",
    "pool1 = tf.nn.max_pool(x, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "result = None\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    result = sess.run(pool1)\n",
    "\n",
    "print(\"image after pooling\", result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(result[0, :, :, 0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### StandardNetworks vs ConvNetworks\n",
    "\n",
    "En las celdas anteriores se mostró como funcionan las convoluciones y el subsampling de imágenes, se mostró como usarlas en tensorflow. En lo que queda del notebook se mostrara lo siguiente:\n",
    "\n",
    "    1. Construir, entrenar y probar una red estándar para clasificar lenguaje de señas\n",
    "    2. Construir, entrenar y probar una red ConvNet  para clasificar lenguaje de señas\n",
    "    3. Usar un ConvNet con arquitectura LeNet-5 para clasificar cuando una imagen tiene un rostro humano o no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Lenguaje de señas\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/2/21/Lengua_de_Signos_%28Bonet%2C_1620%29_B%2C_C%2C_D.jpg\" width=\"180px\">\n",
    "\n",
    "En las próximas celdas vamos usar una red para clasificar lenguaje de señas. La entrada de la red es una imagen de una mano haciendo una seña y la salida de la red es letra del alfabeto que corresponde a esa señal hecha por la mano.\n",
    "\n",
    "##### Datos\n",
    "\n",
    "Los datos para este experimento son un subconjunto del dataset que se puede encontrar en [Kaggle - Sign Language MNIST](https://www.kaggle.com/datamunge/sign-language-mnist)\n",
    "\n",
    "##### Conocimiento previo\n",
    "\n",
    "En el notebook [Notebook 1](notebook2.ipynb) se usaron herramientas como pandas, scikit-learn y tensorflow para definir redes y se realizaron los seguientes pasos:\n",
    "\n",
    "1. Preparar los datos en un conjunto de entrenamiento y otro de pruebas\n",
    "2. Definir las variables y las operaciones de la red\n",
    "3. Definir las operaciones de aprendizaje de la red\n",
    "4. Inicializar la red en una sesión de tensorflow\n",
    "5. Entrenar la red con las operaciones de aprendizaje durante (n) epocas\n",
    "6. Medir la precisición de la red y probar la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sing_hand_data = pd.DataFrame.from_csv('./data/hands_signs.csv', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(sing_hand_data['letter'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sing_hand_data['label'] = LabelEncoder().fit_transform(sing_hand_data['letter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sing_hand_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(sing_hand_data['path'], sing_hand_data['label'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "im = cv2.imread(sing_hand_data[\"path\"][36], 0)\n",
    "print(\"Letter: \", sing_hand_data[\"letter\"][36])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(im, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#helper functions\n",
    "def get_images(images_path, newaxis=False):\n",
    "    images = []\n",
    "    for path in images_path:\n",
    "        if newaxis:\n",
    "            im = cv2.imread(path, 0)[:, :, np.newaxis].astype(np.float32)\n",
    "        else:\n",
    "            im = cv2.imread(path, 0)\n",
    "        images.append(im)\n",
    "\n",
    "    return np.array(images)\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy_ = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy_ * len(batch_x))\n",
    "    return total_accuracy / num_examples\n",
    "\n",
    "signs_labels = [chr(i) for i in range(ord('A'), ord('Z')+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Red estándar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "x = tf.placeholder(tf.float32, (None, 28,28), name=\"X\") \n",
    "y = tf.placeholder(tf.int32, (None), name=\"Y\")\n",
    "y_one_hot = tf.one_hot(y, 24)\n",
    "\n",
    "# parameters layer 1\n",
    "_x = flatten(x)\n",
    "b1 = tf.get_variable(\"b1\", initializer = np.zeros(392, dtype=np.float32))\n",
    "W1 = tf.get_variable(\"W1\", (392, 784), initializer = tf.truncated_normal_initializer())\n",
    "Z1 = tf.add(tf.tensordot(_x, tf.transpose(W1), [[1], [0]]), b1)\n",
    "A1 = tf.nn.relu(Z1)\n",
    "\n",
    "# parameters layer 2\n",
    "b2  = tf.get_variable(\"b2\", initializer = np.zeros(196, dtype=np.float32))\n",
    "W2 = tf.get_variable(\"W2\", (196, 392), initializer = tf.truncated_normal_initializer())\n",
    "Z2 = tf.add(tf.tensordot(A1, tf.transpose(W2), [[1], [0]]), b2)\n",
    "A2 = tf.nn.relu(Z2)\n",
    "\n",
    "# parameters output layer\n",
    "W_l = tf.get_variable(\"W_l\", (24, 196), initializer=tf.truncated_normal_initializer())\n",
    "b_l = tf.get_variable(\"b_l\", initializer=np.zeros(24, dtype=np.float32))\n",
    "\n",
    "logits = tf.add(tf.tensordot(A2, W_l, [[1], [1]]), b_l)\n",
    "\n",
    "# trainning\n",
    "entropy   = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_one_hot)\n",
    "loss      = tf.reduce_mean(entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train     = optimizer.minimize(loss)\n",
    "correct   = tf.equal(tf.argmax(logits, 1), tf.argmax(y_one_hot, 1))\n",
    "accuracy  = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 21\n",
    "EVALUATE_EVERY_N_EPOCHS = 5\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(x_train)\n",
    "    \n",
    "    t0 = time.time()\n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = get_images(x_train[offset:end]), y_train[offset:end]\n",
    "            sess.run(train, feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "        if (epoch % EVALUATE_EVERY_N_EPOCHS) == 0:\n",
    "            train_accuracy = evaluate(get_images(x_train), y_train)\n",
    "            validation_accuracy = evaluate(get_images(x_test), y_test)\n",
    "            fortmat_string = \"EPOCH({})\\t -> Train Accuracy = {:.3f} | Validation Accuracy = {:.3f}\"\n",
    "            print(fortmat_string.format(epoch, train_accuracy, validation_accuracy))\n",
    "    t1 = time.time()\n",
    "    total = t1-t0\n",
    "    print(\"trainning elapsed time\", round(total, 2), \"seconds\")\n",
    "    saver.save(sess, 'networks_std')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Predicción\n",
    "\n",
    "En la siguiente celda se probara el modelo sobre nuevos imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "signs_images_path = glob.glob(\"./images/signs/*.png\")\n",
    "signs_images = [cv2.resize(im, (28,28)) for im in get_images(signs_images_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "preds = None\n",
    "logs  = None\n",
    "pred_labels = None\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './networks_std_v1')\n",
    "    prediction = tf.nn.softmax(logits)\n",
    "    preds, logs = sess.run([prediction, logits], feed_dict={ x: signs_images })\n",
    "    pred_labels = np.argmax(preds, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig, draws = plt.subplots(3,3, figsize=(12,12))\n",
    "draws = draws.reshape(-1)\n",
    "fig.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "\n",
    "for idx in range(9):\n",
    "    draws[idx].set_title(signs_images_path[idx].split(\"/\")[-1] + \"- Pred:\" + signs_labels[pred_labels[idx]])\n",
    "    im =  cv2.resize(signs_images[idx], (28,28))\n",
    "    draws[idx].imshow(im, cmap=\"gray\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.argmax(logs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "signs_labels[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Numero de parámetros\n",
    "\n",
    "Ahora vamos a calcular el numero de parámetros de la red de señas para esto usaremos los parámetros W's y b's\n",
    "con el método `get_shape` y `as_list` esto retorna un lista con las dimensiones de ese parámetro\n",
    "ejemplo:\n",
    "\n",
    "`W1.get_shape().as_list()` retorna `[392, 784]` vamos a crear un método para extraer el número total de parámetros\n",
    "de la red pasandole una lista de las variable que representan estos parámetros que son W's y b's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_total_params(params_list):\n",
    "    total_params = 0\n",
    "    for param in params_list:\n",
    "        param_dim = param.get_shape().as_list()\n",
    "        \n",
    "        total_param_dimension = 1\n",
    "        for num in param_dim:\n",
    "            total_param_dimension = total_param_dimension * num\n",
    "            \n",
    "        total_params = total_params + total_param_dimension\n",
    "        \n",
    "    return [total_params, '{:,}'.format(total_params)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "param_numbers = get_total_params([W1, b1, W2, b2, W_l, b_l])\n",
    "param_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mark_text = \"#### Standard Network Total Parameters = {} \".format(param_numbers[1])\n",
    "display(Markdown(mark_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "x = tf.placeholder(tf.float32, (None, 28,28, 1), name=\"X\") \n",
    "y = tf.placeholder(tf.int32, (None), name=\"Y\")\n",
    "y_one_hot = tf.one_hot(y, 24)\n",
    "\n",
    "# parameters layer 1\n",
    "b1 = tf.get_variable(\"b1\", initializer = np.zeros(16, dtype=np.float32))\n",
    "W1 = tf.get_variable(\"W1\", (8, 8, 1, 16), initializer = tf.truncated_normal_initializer())\n",
    "Z1 = tf.nn.conv2d(x, W1, strides=[1, 3, 3, 1], padding='VALID') + b1\n",
    "A1 = tf.nn.relu(Z1)\n",
    "\n",
    "b2_ = tf.get_variable(\"b2_\", initializer = np.zeros(32, dtype=np.float32))\n",
    "W2_ = tf.get_variable(\"W2_\", (4, 4, 16, 32), initializer = tf.truncated_normal_initializer())\n",
    "Z2_ = tf.nn.conv2d(A1, W2_, strides=[1, 3, 3, 1], padding='VALID') + b2_\n",
    "A2_ = flatten(tf.nn.relu(Z1))\n",
    "\n",
    "\n",
    "# parameters layer 2\n",
    "W2 = tf.get_variable(\"W2\", (784, 196), initializer = tf.truncated_normal_initializer())\n",
    "b2  = tf.get_variable(\"b2\", initializer = np.zeros(196, dtype=np.float32))\n",
    "Z2 = tf.add(tf.tensordot(A2_, W2, [[1], [0]]), b2)\n",
    "A2 = tf.nn.relu(Z2)\n",
    "\n",
    "# parameters output layer\n",
    "W_l = tf.get_variable(\"W_l\", (196, 24), initializer=tf.truncated_normal_initializer())\n",
    "b_l = tf.get_variable(\"b_l\", initializer=np.zeros(24, dtype=np.float32))\n",
    "\n",
    "logits = tf.add(tf.tensordot(A2, W_l, [[1], [0]]), b_l)\n",
    "\n",
    "# trainning\n",
    "entropy   = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_one_hot)\n",
    "loss      = tf.reduce_mean(entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train     = optimizer.minimize(loss)\n",
    "correct   = tf.equal(tf.argmax(logits, 1), tf.argmax(y_one_hot, 1))\n",
    "accuracy  = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 21\n",
    "EVALUATE_EVERY_N_EPOCHS = 5 # epochs\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(x_train)\n",
    "\n",
    "    t0 = time.time()\n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = get_images(x_train[offset:end], newaxis=True), y_train[offset:end]\n",
    "            sess.run(train, feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "        if (epoch % EVALUATE_EVERY_N_EPOCHS) == 0:\n",
    "            train_accuracy = evaluate(get_images(x_train, newaxis=True), y_train)\n",
    "            validation_accuracy = evaluate(get_images(x_test, newaxis=True), y_test)\n",
    "            fortmat_string = \"EPOCH({})\\t -> Train Accuracy = {:.3f} | Validation Accuracy = {:.3f}\"\n",
    "            print(fortmat_string.format(epoch, train_accuracy, validation_accuracy))\n",
    "    t1 = time.time()\n",
    "    total = t1-t0\n",
    "    print(\"trainning elapsed time\", round(total, 2), \"seconds\")\n",
    "    saver.save(sess, 'networks_conv_v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "preds = None\n",
    "logs  = None\n",
    "pred_labels = None\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './networks_conv_v1')\n",
    "    prediction = tf.nn.softmax(logits)\n",
    "    preds, logs = sess.run([prediction, logits], feed_dict={ x: [x_[:,:, np.newaxis] for x_ in signs_images] })\n",
    "    pred_labels = np.argmax(preds, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig, draws = plt.subplots(3,3, figsize=(12,12))\n",
    "draws = draws.reshape(-1)\n",
    "fig.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "\n",
    "for idx in range(9):\n",
    "    draws[idx].set_title(signs_images_path[idx].split(\"/\")[-1] + \"- Pred:\" + signs_labels[pred_labels[idx]])\n",
    "    im =  cv2.resize(signs_images[idx], (28,28))\n",
    "    draws[idx].imshow(im, cmap=\"gray\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "param_numbers = get_total_params([W1, b1, W2_, b2_, W2, b2, W_l, b_l])\n",
    "param_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mark_text = \"#### ConvNet Total Parameters = {} \".format(param_numbers[1])\n",
    "display(Markdown(mark_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### LeNet-5 Architecture\n",
    "\n",
    "<img src=\"https://moisesvw.github.io/img/lenet-5.png\">\n",
    "fuente: [Yan LeCun](http://yann.lecun.com/exdb/lenet/)\n",
    "\n",
    "La estructura de esta red es la siguiente:\n",
    "- Imagen de entrada de 32x32 pixeles\n",
    "- Convolución 1 kernel(5, 5), 6 filtros\n",
    "- Submuestreo con Maxpooling kernel(2,2), slides(2,2)\n",
    "- Convolución 2 kernel(5, 5), 16 filtros\n",
    "- Submuestreo con Maxpooling kernel(2,2), slides(2,2)\n",
    "- red estandar 120\n",
    "- red estandar 84\n",
    "- salida 10 (softmax)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Preparación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "images_path = glob.glob(\"./data/faces/**/*.jpg\")\n",
    "labels = { 'faces': 1, 'no_faces': 0 }\n",
    "data = pd.DataFrame([ {'path': x, 'label': labels[x.split(\"/\")[-2]]} for x in images_path]).sample(4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data['path'], data['label'], test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "x = tf.placeholder(tf.float32, (None, 80,80, 1), name=\"X\") \n",
    "y = tf.placeholder(tf.int32, (None), name=\"Y\")\n",
    "y_one_hot = tf.one_hot(y, 2)\n",
    "\n",
    "# parameters layer 1\n",
    "W1 = tf.get_variable(\"W1\", (5, 5, 1, 6), initializer = tf.truncated_normal_initializer())\n",
    "b1 = tf.get_variable(\"b1\", initializer = np.zeros(6, dtype=np.float32))\n",
    "Z1 = tf.nn.conv2d(x, W1, strides=[1, 1, 1, 1], padding='VALID') + b1\n",
    "A1 = tf.nn.relu(Z1)\n",
    "A1max_pool = tf.nn.max_pool(A1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "\n",
    "# parameters layer 2\n",
    "W2 = tf.get_variable(\"W2\", (5, 5, 6, 16), initializer = tf.truncated_normal_initializer())\n",
    "b2 = tf.get_variable(\"b2\", initializer = np.zeros(16, dtype=np.float32))\n",
    "Z2 = tf.nn.conv2d(A1max_pool, W2, strides=[1, 1, 1, 1], padding='VALID') + b2\n",
    "A2 = tf.nn.relu(Z2)\n",
    "A2max_pool = tf.nn.max_pool(A2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "A2flat = flatten(A2max_pool)\n",
    "\n",
    "# parameters layer 3\n",
    "W3 = tf.get_variable(\"W3\", (4624, 120), initializer = tf.truncated_normal_initializer())\n",
    "b3 = tf.get_variable(\"b3\", initializer = np.zeros(120, dtype=np.float32))\n",
    "Z3 = tf.add(tf.tensordot(A2flat, W3, [[1], [0]]), b3)\n",
    "A3 = tf.nn.relu(Z3)\n",
    "\n",
    "# parameters layer 4\n",
    "W4 = tf.get_variable(\"W4\", (120, 84), initializer = tf.truncated_normal_initializer())\n",
    "b4  = tf.get_variable(\"b4\", initializer = np.zeros(84, dtype=np.float32))\n",
    "Z4 = tf.add(tf.tensordot(A3, W4, [[1], [0]]), b4)\n",
    "A4 = tf.nn.relu(Z4)\n",
    "\n",
    "# parameters output layer\n",
    "W_l = tf.get_variable(\"W_l\", (84, 2), initializer=tf.truncated_normal_initializer())\n",
    "b_l = tf.get_variable(\"b_l\", initializer=np.zeros(2, dtype=np.float32))\n",
    "\n",
    "logits = tf.add(tf.tensordot(A4, W_l, [[1], [0]]), b_l)\n",
    "\n",
    "# trainning\n",
    "entropy   = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=y_one_hot)\n",
    "loss      = tf.reduce_mean(entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train     = optimizer.minimize(loss)\n",
    "correct   = tf.equal(tf.argmax(logits, 1), tf.argmax(y_one_hot, 1))\n",
    "accuracy  = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 21\n",
    "EVALUATE_EVERY_N_EPOCHS = 5 # epochs\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(x_train)\n",
    "\n",
    "    t0 = time.time()\n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = get_images(x_train[offset:end], newaxis=True), y_train[offset:end]\n",
    "\n",
    "            sess.run(train, feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "        if (epoch % EVALUATE_EVERY_N_EPOCHS) == 0:\n",
    "            train_accuracy = evaluate(get_images(x_train, newaxis=True), y_train)\n",
    "            validation_accuracy = evaluate(get_images(x_test, newaxis=True), y_test)\n",
    "            fortmat_string = \"EPOCH({})\\t -> Train Accuracy = {:.3f} | Validation Accuracy = {:.3f}\"\n",
    "            print(fortmat_string.format(epoch, train_accuracy, validation_accuracy))\n",
    "    t1 = time.time()\n",
    "    total = t1-t0\n",
    "    print(\"trainning elapsed time\", round(total, 2), \"seconds\")\n",
    "    saver.save(sess, 'lenet-5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_images = [ cv2.resize(x, (80,80)) for x in get_images(glob.glob(\"./images/faces/*.jpg\")) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "preds = None\n",
    "logs  = None\n",
    "pred_labels = None\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './lenet-5')\n",
    "    prediction = tf.nn.softmax(logits)\n",
    "    preds, logs = sess.run([prediction, logits], feed_dict={ x: [x_[:,:, np.newaxis] for x_ in test_images] })\n",
    "    pred_labels = np.argmax(logs, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "labels = { 1: \"Human\", 0: \"No Human\" }\n",
    "fig, draws = plt.subplots(1,5, figsize=(12,12))\n",
    "draws = draws.reshape(-1)\n",
    "fig.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "\n",
    "for idx in range(len(pred_labels)):\n",
    "    draws[idx].set_title(\"Pred:\" + labels[pred_labels[idx]])\n",
    "    im =  test_images[idx]\n",
    "    draws[idx].imshow(im, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
